{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "      <td><div align=\"left\"><font size=\"20\" >Camera Calibration</font></div></td>\n",
    "     <td><img src=\"images/RVSS-logo.png\" width=\"400\"></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to investigate how we can calibrate a camera to determine the camera's intrinsic and extrinsic parameters. When we calibrate a camera we take an image of a calibration rig and associate certain points/features within that image to real-world coordinates. We can then determine the camera parameters using an optimisation method, for example least-squares.  \n",
    "\n",
    "Before we dive into real-world data we are going to create a situation where we know the camera parameters, the real-world points and where these points would lie if an image was taken from a specific pose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: machinevision-toolbox-python in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.5.4)\n",
      "Requirement already satisfied: spatialmath-python==0.8.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.8.9)\n",
      "Requirement already satisfied: opencv-python in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from machinevision-toolbox-python) (4.2.0.32)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from machinevision-toolbox-python) (1.19.4)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from machinevision-toolbox-python) (3.1.3)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from machinevision-toolbox-python) (1.4.1)\n",
      "Requirement already satisfied: ansitable in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from machinevision-toolbox-python) (0.9.5)\n",
      "Requirement already satisfied: spatialmath-python==0.8.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.8.9)\n",
      "Requirement already satisfied: colored in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from spatialmath-python==0.8.9) (1.4.2)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from machinevision-toolbox-python) (1.19.4)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from machinevision-toolbox-python) (3.1.3)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from machinevision-toolbox-python) (1.4.1)\n",
      "Requirement already satisfied: ansitable in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from machinevision-toolbox-python) (0.9.5)\n",
      "Requirement already satisfied: colored in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from spatialmath-python==0.8.9) (1.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->machinevision-toolbox-python) (1.1.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from machinevision-toolbox-python) (1.19.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->machinevision-toolbox-python) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->machinevision-toolbox-python) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->machinevision-toolbox-python) (2.8.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->machinevision-toolbox-python) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->machinevision-toolbox-python) (50.3.2)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from machinevision-toolbox-python) (1.19.4)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->machinevision-toolbox-python) (1.15.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from machinevision-toolbox-python) (1.19.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import sys\n",
    "!{sys.executable} -m pip install machinevision-toolbox-python spatialmath-python==0.8.9 # install MVTB and spatialmath\n",
    "\n",
    "import matplotlib\n",
    "import ipywidgets as wdg\n",
    "\n",
    "from machinevisiontoolbox import Image, CentralCamera\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from spatialmath import SE3, SO3\n",
    "from spatialmath import base\n",
    "\n",
    "from camera_calib_helpers import CreateSimulatedCamera\n",
    "\n",
    "np.set_printoptions(linewidth=120, formatter={'float': lambda x: f\"{x:8.4g}\" if abs(x) > 1e-10 else f\"{0:8.4g}\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration Rig\n",
    "\n",
    "RVSS2021 will be using the following calibration rig which consists of 12 dots forming three 6cm squares on three planes. We will store the real-world 3D coordinates that reflect the markers on the calibration target in the matrix `P_calib`. We will be using `P_calib` throughout this coding session.\n",
    "\n",
    "![calibration](images/calibration-fixture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = 0.01 # centimetre to metre conversion factor\n",
    "\n",
    "P_calib = np.array([\n",
    "    [ 0,  -12.2, 12.2],\n",
    "    [ 0,   -6.2, 12.2],\n",
    "    [ 0,  -12.2,  6.2],\n",
    "    [ 0,   -6.2,  6.2],\n",
    "    [ 6.2,  0,   12.2],\n",
    "    [12.2,  0,   12.2],\n",
    "    [ 6.2,  0,    6.2],\n",
    "    [12.2,  0,    6.2]\n",
    "]).T * cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrating A Simulated Camera\n",
    "\n",
    "## Simulate a Camera\n",
    "\n",
    "First, we will simulate a black box camera. While we know the pose and chateristics of this camera (you can check them out in the `CreateSimulatedCamera` function, but we will assume we do not and see if we can find the camera extrinsic and intrinsic parameters ourself using simulated calibration data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_camera = CreateSimulatedCamera()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object `unknown_camera` is a model of the camera and was computed using the `CreateCameraModel` function in the `camera_calib_helpers.py` script. For now we will pretend we don't know it's characteristics, and that its pose is unknown with respect to the calibration target.\n",
    "\n",
    "However **we do know** the world coordinates of the markers.\n",
    "\n",
    "We can create an \"artificial\" image of the 3D points by projecting these points onto the 2D image plane within our simulated camera, by using the code below. *We can only do this because we know camera characteristics, as well as the pose of the camera and the locations of the 3D points with respect to the world frame.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_camera.plot(P_calib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projecting the 3D coordinates of the calibration target markers onto the  into 2D image plane coordinates using the camera object's `project` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = unknown_camera.project(P_calib)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, with real camera calibration these 2D coordinates must be obtained by taking an image and finding the coordinates of the points in the captured image. We will be using a real-image later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Camera Matrix \n",
    "\n",
    "We can noe compute the camera calibration from the calibration data, the real-world coordinates `P_calib` and the 2D image coordinates `p`.\n",
    "\n",
    " * `P_calib`, is an array of 3D points which is a $3 \\times N$ matrix, one point per column (which would be found by measuring the points in the real-world)\n",
    " * `p`, is an array of 2D points which is a $2 \\times N$ matrix, one point per column (which would be found in the captured image)\n",
    "    \n",
    "Importantly, the points correspond, that is the $i^{th}$ column of `p` is the projection of the 3D point in the $i^{th}$ column of `P_calib`.\n",
    "\n",
    "The camera matrix $C$ can be computed by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = CentralCamera.camcal(P_calib, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the small residual is an encouraging sign, it indicates that the data is a good fit to the projection model of a perspective camera. *This is to expected in this case as we found `p` by projecting the 3D points using our artificial camera model*\n",
    "\n",
    "The value of the camera matrix is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intrinsic and extrinsic parameters of the camera are jumbled up in these 12 numbers, but we can unjumble them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = CentralCamera.invcamcal(C)\n",
    "print(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intrinsic and extrinsic parameters have been encapsulated in a toolbox `CentralCamera` object.\n",
    "\n",
    "**Note:** When computing the camera matrix the focal length and the pixel dimensions are multiplied together, so it's not possible to determine them individually.  This function assumes that the pixel dimension is 1 and the focal length has units of pixels rather than metres (hence the large values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intrinsic parameters are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the values in the top left are half image width and height we specified and that focal length (1500) is a factor of the length we provided into the `CreateSimulatedCamera` function. Naturally, because we are passing in exact data then getting back exact values is to be expected.\n",
    "\n",
    "The extrinsic parameters, the pose, of the camera with respect to the world calibration frame, is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tcam = camera.pose\n",
    "print(Tcam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates the position of the camera is (1, -1) on the ground plane, and slightly above the ground (z=0.1).\n",
    "\n",
    "The orientation of the camera can be extracted from its SE(3) pose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpy = Tcam.rpy(order='zyx', unit='deg')\n",
    "rpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which indicates the orientation of the camera can be described by three consecutive rotations, in the following order:\n",
    "\n",
    "1. a rotation of 50° about the z-axis, which points the camera toward the calibration target\n",
    "2. a rotation of 2° about the y-axis, which indicates some imperfection, a small twist about the camera axis\n",
    "3. a rotation of -92° about the x-axis, which makes the camera's z-axis (it's line of sight) approximately parallel to the ground plane, again some imperfection so the camera is actually pointing slightly toward the floor.\n",
    "\n",
    "That is all that is required to determine the camera charateristics. You simply need two sets of points, one from the real-world and one with the corresponding 2D image coordinates, you need at least 6 corresponding points.\n",
    "\n",
    "You can choose to peek at the \"unknown\" camera model in `CreateCameraModel.py` and see that the parameters we have estimated simply from 3D and 2D data points matches the parameters of that camera.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Ground Plane Coordinates to the Image Plane\n",
    "\n",
    "The extrinsic parameters indicate where the camera is with respect to the world frame. For our project we want to know the coordinate of a point on the ground relative to the camera which is mounted on a robot moving across a ground plane. We define a pair of coordinates frames as per this diagram\n",
    "\n",
    "![frames](images/coordinate-frames.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The robot frame {R} is attached to the robot with its x-axis to the right, y-axis forward and z-axis upward. This frame sits on the ground plane, as does the world-coordinate frame we used for calibration (shown in the first figure in this notebook).\n",
    "\n",
    "The camera frame {C} is attached to the camera and has its x-axis to the right, y-axis downwards and z-axis (line of sight) forward.\n",
    "\n",
    "The relative pose of frame {C} with respect to frame {R} has two components: a translation $t$ and a rotation $\\mathbf{R}$.\n",
    "\n",
    "The translation is purely in the z-direction, and our calibration process gave us the height of the camera above the ground.  Therefore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [0, 0, Tcam.t[2]] # Tcam.t[2] is the position of the camera in the world frame z-axis\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rotate the z-axis from upwards (frame {R}) to forwards (in frame {C}) is a rotation of -90° about the x-axis.  However our camera calibration indicated the angle was slightly different to that, -92° in fact.  There is also a slight rotation about the y-axis of 2°.  We will assume that there is no error in the rotation about the z-axis (there is actually no way to identity if there was).  \n",
    "\n",
    "Therefore the orientation of the camera frame {C} relative to the robot frame {R} is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = SO3.Ry(rpy[1], 'deg') * SO3.Rx(rpy[0], 'deg')\n",
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can combine the translation and rotation into a single homogeneous transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = SE3(t) * SE3.SO3(R)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `SO3` and `SE3` are classes defined in [Spatial Maths for Python](https://github.com/petercorke/spatialmath-python) and encapsulate the functionality that Tom introduced in B1 on Monday.\n",
    "\n",
    "The camera model that was estimated from the camera matrix has valid intrinsic parameters but we want to change the  extrinsics.  Now we care about where the camera is with respect to {R} not where it is with respect to the calibration frame, so we will override the extrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.pose = T\n",
    "print(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this model to investigate how world points are mapped to the image plane.\n",
    "\n",
    "Points on the ground 0.5m and 0.6m in front of the camera appear at the following locations on the image plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([[0, 0.4, 0], [0, 0.6, 0]]).T\n",
    "camera.project(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second column corresponds to the point that is further from the camera and it is ~13 pixels higher in the image.\n",
    "\n",
    "We note that the u-coordinate of both points is close to the u-coordinate of the principal point (640), the centre of the image, which indicates that the world point is close to the optical axis (as the x-coordinate of 0 would indicate).  Remember that the camera is slightly skewed with respect to the robot frame.\n",
    "\n",
    "The camera matrix, that encodes the intrinsic and extrinsic parameters of the camera, is now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping image plane coordinates to the ground plane\n",
    "\n",
    "In the previous section we intuitively worked through how we can map ground points into the image plane. Now we will see how can we do the opposite, but we will take a more principled approach. \n",
    "\n",
    "Points on the ground plane have a z-coordinate of zero.  The camera projection equation, in matrix form, is\n",
    "$$\n",
    "\\tilde{p} = \\begin{pmatrix} c_1 & c_2 & c_3  & c_4 \\end{pmatrix} \\begin{pmatrix} X \\\\ Y \\\\ Z \\\\ 1 \\end{pmatrix}\n",
    "$$\n",
    "where $c_i$ is the $i^{th}$ column of the camera matrix.  Since $Z=0$ we can rewrite as \n",
    "\n",
    "\\begin{align}\n",
    "\\tilde{p} & = \\begin{pmatrix} c_1 & c_2 & c_4 \\end{pmatrix} \\begin{pmatrix} X \\\\ Y \\\\ 1 \\end{pmatrix} \\\\\n",
    "          & = \\mathbf{H} \\begin{pmatrix} X \\\\ Y \\\\ 1 \\end{pmatrix}\n",
    "\\end{align}\n",
    "where $(X, Y)$ is a point on the ground plane with respect to the camera frame which has the Y-axis forward and the X-axis to the right.\n",
    "\n",
    "In this case $\\mathbf{H}$ is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = camera.C[:,[0,1,3]]\n",
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is both square and non-singular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which means we have an invertible mapping between 2D points in the image plane and 2D points on the ground plane, both expressed in homogenous form.  Such a transformation is called an *homography*.\n",
    "\n",
    "**Note that in general we cannot map a 2D point to a 3D point, since a 2D image plane coordinate corresponds to a ray in space -- an infinite number of points.  However the constraint that the point lies on the ground plane makes a unique solution possible, it is the point where that ray intersects the ground plane.**\n",
    "\n",
    "Consider a point in the image plane at $(300, 600)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (300, 600)  # make homogeneous\n",
    "P_groundplane = base.h2e(np.linalg.inv(H) @ base.e2h(p))\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and this is corresponding point coordinate on the ground plane. x=-0.027 indicates it is to the left of the robot, and y=0.117 indicates it is in-front of the robot.\n",
    "\n",
    "We can cross check this by reprojecting that world point back to the image plane using our camera model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.vstack((P_groundplane, 0))  # point is on the ground, add Z=0\n",
    "print(P)\n",
    "camera.project(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we obtain, as we should do, the image plane coordinate that we started with.\n",
    "\n",
    "## Summary\n",
    "\n",
    "1. Using corresponding 3D and 2D data we can estimate a camera matrix.\n",
    "2. We can untangle the elements of that matrix into intrinsic and extrinsic parameters.\n",
    "3. We use an estimated camera model to form an homography which maps between image plane and ground plane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you get to apply what you've learned above using a real image of a calibration target. The next section of code will display an image and a text widget showing an $8 \\times 2$ array. \n",
    "\n",
    "You will need to:\n",
    "\n",
    "1. click the centre of each point as accurately as you can, in the order given by the diagram at the top of this notebook.\n",
    "2. If you make a mistake, do a right-click and will undo the last point you clicked (and remove the marker)\n",
    "\n",
    "Once you are happy with the points you selected, move onto the next set of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"839\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c85219fdee14f79b89869a7406dcdba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='[[      -1       -1]\\n [      -1       -1]\\n [      -1       -1]\\n [      -1       -1]\\n [    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display image\n",
    "image = Image('images/calib_0.png', grey=True)\n",
    "fig = matplotlib.pyplot.figure()\n",
    "plt.imshow(image.image, cmap='gray')\n",
    "\n",
    "# Variables, p will contains clicked points, idx contains current point that is being selected\n",
    "p = np.ones((8,2)) * -1\n",
    "idx = 0\n",
    "\n",
    "# Create text area widget to display clicked locations\n",
    "txt = wdg.Textarea(value=str(p), placeholder='', description='Clicked Point:', disabled=False)\n",
    "display(txt)\n",
    "\n",
    "# Code to pick points and display in text widget\n",
    "def onclick(event):\n",
    "    global p, idx\n",
    "    \n",
    "#     txt.value = str(event)\n",
    "    if event.button == 1:\n",
    "        # left mouse click, add point and increment by 1\n",
    "        p[idx, 0] = event.xdata\n",
    "        p[idx, 1] = event.ydata\n",
    "        idx = idx + 1\n",
    "    elif event.button == 3:\n",
    "        # right click, go back to previous point\n",
    "        idx -= 1\n",
    "        p[idx, 0] = -1\n",
    "        p[idx, 1] = -1\n",
    "        \n",
    "    txt.value = str(p) \n",
    "    idx = np.min(np.max(idx, 0), 7) # to keep within bounds\n",
    "    \n",
    "ka = fig.canvas.mpl_connect('button_press_event', onclick)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   99.23    225.4    95.52    222.9    403.5    511.1    404.7    514.8]\n",
      " [   77.45    103.4      211    220.9    91.05    44.05    217.2    199.9]]\n"
     ]
    }
   ],
   "source": [
    "p = p.T # we actually need a 2 x 8 matrix for the function below, so simply take the transpose\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now estimate the camera matrix, and extract the intrinsic and extrinsic parameters.  Compute the homography and see if you can sensibly map points between image plane and ground plane.\n",
    "\n",
    "**Once you have the camera intrinsic matrix K, revist the Aruco marker exercise from A1 using the proper value of K, and see if the estimates of marker pose agree with what you can measure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residual is 0.767 px\n",
      "[[       1        0        0]\n",
      " [       0       -1        0]\n",
      " [       0        0       -1]]\n",
      "[[   569.8        0    311.7]\n",
      " [       0    578.5    253.1]\n",
      " [       0        0        1]]\n"
     ]
    }
   ],
   "source": [
    "C = CentralCamera.camcal(P_calib, p)\n",
    "camera = CentralCamera.invcamcal(C)\n",
    "print(camera.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
